# 職務経歴書

## 山下慶倫
<!-- ![ハル](/Users/rasuharu/Documents/SDIM1593.jpeg) -->
<div style="background: url(/Users/rasuharu/Documents/SDIM1593.jpeg) 50% 50% no-repeat; background-size:cover; position: absolute; top: 0; left: 0; width: 100%; height: 100%; display: flex; justify-content: center; align-items: center;">
<div style="background: rgba(0,0,0,0.5); padding: 30px 40px; font-size: 3.0em; color: #fff;">Yoshinori Yamashita</div>
</div>

<div style="page-break-after: always;"></div>

# 概要

|基本情報||
|---|-----|
|Name|山下慶倫 |
|年齢	|31|
|最寄駅|	押上|
|GitHub|[yoshinori77](https://github.com/yoshinori77)|

<br />

## 言語
- Python：4年
- Scala：1年
- JavaScript：1.5年
- Ruby：1.5年

## フレームワーク
- scikit-learn：4年
- Keras：2年
- Flask：2年
- Ruby on Rails：1年

## データ分析経験
- 構造化データ：3年
- 時系列データ：1.5年
- 自然言語データ：0.5年
- 画像データ：0.5年

<div style="page-break-after: always;"></div>

# 概要
## ツール
- GCP：1年
- AWS：3年
- Airflow：1年
- Tableau・BI：1.5年
- Spark：1.5年
- Hive：1.5年
- Hadoop：1.5年
- Docker：2年
- Git：4年
- Slack：3年

## 強み
- 機械学習・データエンジニアリングに対応できます。

## 趣味
- 猫の世話
- 漫画・アニメ
- 美味しいご飯を食べること

<div style="page-break-after: always;"></div>

# 職務経歴

## 2021/2 - 現在 : パーソルキャリア株式会社

### ポジション
- データエンジニア
- データサイエンティスト

### 大規模レコメンドシステムの運用保守 & AWS -> GCP移行
- 数億レコードのテーブルを分散処理（Spark）で集計などを行う前処理を実施
- 複数のモデルを用いてレコメンドし、パイプラインをシェルスクリプトで管理（色々ツライのでAWSからGCPに移行）

### 開発規模
- エンジニア 6名
- PM 1名

### 担当業務
- 基本設計・詳細設計
- 実装（パイプライン構築、機械学習モデル構築、ビッグデータ処理）
- 単体テスト・結合テスト

### 使用言語
- Python
- Scala

### スキル
- 学習・推論パイプラインの構築（Cloud Composer、シェルスクリプト）
- Terraformによるシステム構築の自動化
- Scala・Sparkのビッグデータ処理
- GCP（Vertex AI、Cloud Composer、Cloud Storage、Artifact Registry、Dataproc...）
- AWS（EMR、S3...）
- Python（Numpy）で協調フィルタリングのコサイン類似度を算出する際に、行列演算で処理時間を約1/100に高速化

### コメント
- 稼働しているサービスの運用保守は初めてだったので学びが多かったです。
- 深夜対応、開発の切り戻しなどがあり精神的にも鍛えられました。
- AWSとGCP両方の開発を経験し、スキルアップにつながりました。

<div style="page-break-after: always;"></div>

# 職務経歴
## 2020/6 - 2021/1: パーソルキャリア株式会社
### ポジション
- データエンジニア
- サーバーサイドエンジニア
### 適正年収の自動査定サービス（のロジック部分のシステム構築）
- 従来のメンバーシップ型からジョブ型の雇用に切り替わってゆく中で、どの企業も市場の適正年収は大きな関心事です。
- 転職市場の情報とユーザーの職種、業種、年齢などを照らし合わせて、職種におけるグレード・年収を推定することで適正年収の指標を提供しました。

### 開発規模
- エンジニア 3名
- データサイエンティスト 1人
- PM 1名

### 担当業務
- 要件定義・基本設計・詳細設計
- 実装（推論パイプライン構築、API構築、通知・ログ環境の整備）
- 単体テスト・結合テスト

### 使用言語
- Python

### スキル
- 推論システムの構築
- 形態素解析、IF-IDFなど基本的な自然言語処理
- AWS CloudFormationによるシステム構築の自動化
- Amazon API Gateway & AWS Lambdaを利用したAPI構築
- AWS LambdaとAmazon EFSの連携（学習済みの機械学習モデルを配置）
- AWS Cloud Watch Logs を利用したログ環境の整備

### コメント
- これまでアプリケーションを開発経験が少なかったのですが、諸々の事情でほぼ一人で開発を進めることになり、なんとかやり遂げました。
- 最終的には使用しませんでしたが、SQS、SageMaker、Step Functionsなどにも触れました。

<div style="page-break-after: always;"></div>

# 職務経歴
## 2019/9 - 2020/5: フリーランス

### ポジション
- データアナリスト

### ECサービスの顧客分析
- 顧客満足度（NPS）を機械学習で予測して、サービスの改善（特に販売促進）をすることが目的でした。
- これまでのユーザー全てに同じ施策を打つマスマーケティグから、ユーザーごとに施策を分けるターゲットマーケティングへの転換の一歩に微力ながら貢献できたと自負しております。

### 開発規模
- エンジニア 1名  
- PM 1名

### 担当業務
- 要件定義
- 実装（可視化、前処理、機械学習モデル構築、評価）
- 単体テスト

### 使用言語
- Python

### スキル
- 構造化データの前処理・特徴量エンジニアリング
- 不均衡データへの対策（Over-sampling、Under-sampling、Calibration）
- BigQuery
- Keras
- scikit-learn

<div style="page-break-after: always;"></div>

# 職務経歴
## 2018/11 - 2019/9: フリーランス

### ポジション
- データアナリスト

### 住宅価格査定ロジック構築
- このプロジェクトでは物件の価格査定を自動化することが目的でした。
- これまでは人が価格査定をするか、機械学習で予測していても精度が低く信頼性が低い問題がありました。
- 以前よりも精度の高い機械学習モデルを構築しました。
- Treasure Data等を利用してETLを行いデータエンジニアリングも行いました。

### 開発規模
- エンジニア 2名  
- PM 1名

### 担当業務
- 要件定義
- 実装（可視化、前処理、機械学習モデル構築、評価）
- 単体テスト

### 使用言語
- Python

### スキル
- 構造化データの前処理・特徴量エンジニアリング
- Treasure Data
- Digdagを利用したワークフロー構築
- Embulkを利用したデータ転送
- scikit-learnを用いた機械学習処理
- チーム開発

<div style="page-break-after: always;"></div>

# 職務経歴

## 2017/11 - 2018/10: DATUM STUDIO株式会社

### ポジション
- データアナリスト

### レコメンドシステム構築/WebAPI開発
- アンケートデータからユーザーの求めるアイテムをレコメンドすることで、サービスの価値向上に貢献しました。
- 特に実装フェーズでは前処理、機械学習（分類）、協調フィルタリング、WebAPI構築などを担当しました。
- またダッシュボードの構築も行いました。

### 開発規模
- エンジニア 2名  
- PM 1名

### 担当業務
- 要件定義
- 実装（可視化、前処理、機械学習モデル構築、評価）
- 単体テスト

### 使用言語
- Python

### スキル
- Amazon EC2上にレコメンドシステムを構築
- Flaskを利用したWebAPI構築
- Amazon RDS（MariaDB）
- Amazon S3
- scikit-learn
- Tableau
- チーム開発

### コメント
- 業務でAWSを使用したのは初めてだったので勉強になりました。

<div style="page-break-after: always;"></div>

# 職務経歴

## 2017/5 - 2017/10: 株式会社モノゴコロ

### ポジション
- データアナリスト

### 画像認識を用いたサッカー動画解析
- YOLOというディープラーニングアルゴリズムを用いて物体検出を行いサッカー動画から自動で選手のチームを判別するアプリケーションのプロトタイプを作成しました。
- この技術の発展版として、人を検知することで自動で交通量を調査するアプリケーションを構築しました。

### 開発規模
- エンジニア 1名  
- PM 1名

### 担当業務
- 要件定義
- 実装
- 単体テスト

### 使用言語
- Python
- JavaScript

### スキル
- 画像認識
- OpenCV
- D3.js
- Git

### コメント
- 画像認識やデータ分析に触れるきっかけになりました。


<div style="page-break-after: always;"></div>

# 職務経歴

## 2016/11 - 2017/4: 株式会社モノゴコロ

### ポジション
- サーバーサイドエンジニア

### チャットアプリ
- WebSocketを用いてリアルタイムチャットアプリを実装しました。Ruby on Railsを使用しました。

### 開発規模
- エンジニア 1名  
- PM 1名

### 担当業務
- 実装

### 使用言語
- Ruby
- JavaScript

### スキル
- Ruby on Rails
- PostgreSQL
- Git

### コメント
- Railsの使い方やGitなど開発の基本を学びました。


<div style="page-break-after: always;"></div>

<!-- # 個人活動

## 株取引のアプリケーション作成
### 使用言語
- Python

### スキル
- [Dash](http://dash.plotly.com/)
- [Plotly](https://plotly.com/python/)
- [FastAPI](https://fastapi.tiangolo.com/)
- [Flask](https://flask.palletsprojects.com/)
- [pandas](https://pandas.pydata.org/)
- [Docker](https://www.docker.com/)
- [Poetry](https://python-poetry.org/)

### コメント
- Yahoo Finance USからデータを取得し、ファンダメンタルズ分析で必要な情報を一目でわかるようにまとめたり、グラフ化したりしました。
- そのほかテクニカル分析を行なって将来の株価を分析したり、Dockerで楽に環境構築や管理できています。

<div style="page-break-after: always;"></div> -->

# 個人活動

## Kaggle

[プロフィール](https://www.kaggle.com/yamashita)
### 使用言語
- Python

### スキル
- [pandas](https://pandas.pydata.org/)
- [Numpy](https://numpy.org/)
- [SciPy](https://scipy.org/)
- [LightGBM](https://github.com/microsoft/LightGBM)
- [Keras](https://keras.io/)
- [TensorFlow](https://www.tensorflow.org/)
- [scikit-learn](https://scikit-learn.org/stable/)

### 参加コンペ
- JPX Tokyo Stock Exchange Prediction（2022）
  - [GitHub](https://github.com/yoshinori77/jpx_tokyo_market_prediction)
  - 途中で挫折しました...
- Santander Customer Transaction Prediction（2019）
  - 銅メダルでした。 549/8751（7%）
- Data Science Bowl（2019）
  - ダメでした。1215/3493
### コメント
- Kaggleでデータサイエンスのスキルを磨きました。
- まだまだ結果を出せていないので、今後も粘り強くチャレンジします。
